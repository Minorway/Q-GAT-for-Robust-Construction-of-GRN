{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fc5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0610, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0671, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0818, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0865, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0976, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0973, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1244, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1205, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1338, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1271, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1336, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1513, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1468, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1606, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1752, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1435, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1677, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1883, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1679, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1729, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2017, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1820, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1791, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2121, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2062, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2102, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2051, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2283, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2391, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2371, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2436, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2224, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2361, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2563, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2078, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2465, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2553, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4464, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2721, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2533, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2825, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2602, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2726, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2850, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2414, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2749, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2630, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2730, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2676, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3048, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2683, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2856, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2823, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2939, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3108, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3108, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3060, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3174, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3077, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3273, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3025, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3583, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3162, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2935, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3434, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3056, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3341, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3116, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3257, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3416, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3226, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3310, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3101, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3363, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3473, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3132, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3422, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3263, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3570, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3547, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3236, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3410, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3627, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3041, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3598, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3397, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3858, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3847, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3292, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3310, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3664, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4098, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3790, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3756, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3694, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4026, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3845, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3906, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3876, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3555, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from QuadraticOperation import QuadraticOperation\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class QNN(nn.Module):\n",
    "    def __init__(self, widths):\n",
    "        super(QNN, self).__init__()\n",
    "        self.width = widths\n",
    "        self.w0 = QuadraticOperation(self.width,self.width)\n",
    "    def forward(self, x):\n",
    "        x = self.w0(x)\n",
    "        return x\n",
    "\n",
    "data_dir = './test/'\n",
    "\n",
    "# ntrain = 80\n",
    "# ntest = 40\n",
    "snr_ines= []\n",
    "snr_outes= []\n",
    "ves= []\n",
    "for amp in range(100):\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.001\n",
    "    scheduler_step = 100\n",
    "    scheduler_gamma = 0.5\n",
    "    width=1\n",
    "    sigma=0.01\n",
    "    ampl=amp+1\n",
    "\n",
    "    print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "    s_path=data_dir+'s_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    n_path=data_dir+'n_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    x_path=data_dir+'x_noise_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    \n",
    "    t = torch.arange(0, 200)*0.1\n",
    "    s=torch.load(s_path)\n",
    "    noise=torch.load(n_path)\n",
    "    train_x = torch.load(x_path)\n",
    "    train_y = s\n",
    "    print(train_x.shape)\n",
    "    print(train_y.shape)\n",
    "\n",
    "    \n",
    "    P_xs=torch.sum(s**2)/t.size(0)\n",
    "    P_xn=torch.sum(noise**2)/t.size(0)\n",
    "    SNR_in=10*torch.log10(1+P_xs/P_xn)\n",
    "    snr_ines.append(SNR_in.detach().numpy())\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "\n",
    "    model = QNN(width)\n",
    "    # model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
    "\n",
    "    # print(count_params(model))\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        im = model(train_x)\n",
    "        loss=myloss(im.reshape(1, -1), train_y.reshape(1, -1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('loss',loss)\n",
    "\n",
    "    P_ys=torch.sum(s**2)/t.size(0)\n",
    "    P_yn=torch.sum((im-s)**2)/t.size(0)\n",
    "    SNR_out=10*torch.log10(1+P_ys/P_yn)\n",
    "    V=SNR_out/SNR_in\n",
    "    snr_outes.append(SNR_out.detach().numpy())\n",
    "    ves.append(V.detach().numpy())\n",
    "    torch.save(im,y_path)\n",
    "# torch.save(snr_ines,'snr_ines_1Q1.pt')    \n",
    "# torch.save(snr_outes,'snr_outes_1Q1.pt')  \n",
    "# torch.save(ves,'ves_1Q1.pt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d7bed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0455, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0678, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0826, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.0902, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1007, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1058, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1304, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1242, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1400, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1349, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1497, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1614, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1527, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1764, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1865, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1701, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1797, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1981, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1888, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1888, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2144, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.1978, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2005, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2251, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2249, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2343, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2319, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2493, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2629, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2579, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2696, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2517, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2644, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2857, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2422, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2801, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2779, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2623, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2987, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2892, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3056, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2828, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2959, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3206, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2647, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3138, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.2805, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3117, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3031, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3381, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3019, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3143, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3067, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3355, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3447, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3630, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3403, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3619, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3383, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3602, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3301, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3845, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3515, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3359, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3750, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3341, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3560, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3420, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3621, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3734, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3742, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3694, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3518, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3786, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3797, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3448, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3961, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3634, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.3883, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3839, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3721, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3855, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3896, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3467, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3893, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3901, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4221, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4120, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3663, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4004, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4169, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4317, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4072, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4113, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4187, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4454, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4280, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4288, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.4286, grad_fn=<SumBackward0>)\n",
      "1000 0.001 100 0.5\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "loss tensor(0.3940, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class LNN(nn.Module):\n",
    "    def __init__(self, widths):\n",
    "        super(LNN, self).__init__()\n",
    "        self.width = widths\n",
    "        self.w0 = nn.Linear(self.width,LN*self.width)\n",
    "        self.w1 = nn.Linear(LN*self.width,LN*self.width)\n",
    "        self.w2 = nn.Linear(LN*self.width,LN*self.width)\n",
    "        self.w3 = nn.Linear(LN*self.width,LN*self.width)\n",
    "        self.w4 = nn.Linear(LN*self.width,1*self.width)\n",
    "#         self.w5 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w6 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w7 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w8 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w9 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w10 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w11 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w12 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w13 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w14 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w15 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w16 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w17 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w18 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w19 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w20 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w21 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w22 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w23 = nn.Linear(LN*self.width,LN*self.width)\n",
    "#         self.w24 = nn.Linear(LN*self.width,self.width)\n",
    "    def forward(self, x):\n",
    "        x = self.w0(x)\n",
    "        x =self.w1(x)\n",
    "        x =self.w2(x)\n",
    "        x = self.w3(x)\n",
    "        x =self.w4(x)\n",
    "#         x = self.w5(x)\n",
    "#         x =self.w6(x)\n",
    "#         x =self.w7(x)\n",
    "#         x = self.w8(x)\n",
    "#         x =self.w9(x)\n",
    "#         x = self.w10(x)\n",
    "#         x =self.w11(x)\n",
    "#         x =self.w12(x)\n",
    "#         x = self.w13(x)\n",
    "#         x =self.w14(x)\n",
    "#         x = self.w15(x)\n",
    "#         x =self.w16(x)\n",
    "#         x =self.w17(x)\n",
    "#         x = self.w18(x)\n",
    "#         x =self.w19(x)\n",
    "#         x = self.w20(x)\n",
    "#         x =self.w21(x)\n",
    "#         x =self.w22(x)\n",
    "#         x = self.w23(x)\n",
    "#         x =self.w24(x)\n",
    "        return x\n",
    "\n",
    "data_dir = './test/'\n",
    "\n",
    "# ntrain = 80\n",
    "# ntest = 40\n",
    "snr_ines= []\n",
    "snr_outes= []\n",
    "ves= []\n",
    "LN=3\n",
    "for amp in range(100):\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.001\n",
    "    scheduler_step = 100\n",
    "    scheduler_gamma = 0.5\n",
    "    width=1\n",
    "    sigma=0.01\n",
    "    ampl=amp+1\n",
    "\n",
    "    print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "    s_path=data_dir+'s_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    n_path=data_dir+'n_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    x_path=data_dir+'x_noise_3cos2pi_gaussnoise='+str(sigma*ampl)+'.pt'\n",
    "    t = torch.arange(0, 200)*0.1\n",
    "    s=torch.load(s_path)\n",
    "    noise=torch.load(n_path)\n",
    "    train_x = torch.load(x_path)\n",
    "    train_y = s\n",
    "    print(train_x.shape)\n",
    "    print(train_y.shape)\n",
    "\n",
    "    \n",
    "    P_xs=torch.sum(s**2)/t.size(0)\n",
    "    P_xn=torch.sum(noise**2)/t.size(0)\n",
    "    SNR_in=10*torch.log10(1+P_xs/P_xn)\n",
    "    snr_ines.append(SNR_in.detach().numpy())\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "\n",
    "    model = LNN(width)\n",
    "    # model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
    "\n",
    "    # print(count_params(model))\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        im = model(train_x)\n",
    "        loss=myloss(im.reshape(1, -1), train_y.reshape(1, -1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('loss',loss)\n",
    "\n",
    "    P_ys=torch.sum(s**2)/t.size(0)\n",
    "    P_yn=torch.sum((im-s)**2)/t.size(0)\n",
    "    SNR_out=10*torch.log10(1+P_ys/P_yn)\n",
    "    V=SNR_out/SNR_in\n",
    "    snr_outes.append(SNR_out.detach().numpy())\n",
    "    ves.append(V.detach().numpy())\n",
    "    torch.save(im,y_path)\n",
    "# torch.save(snr_ines,'snr_ines_5L2_LN5.pt')    \n",
    "# torch.save(snr_outes,'snr_outes_5L2_LN5.pt')  \n",
    "# torch.save(ves,'ves_5L2_LN5.pt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065c26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
